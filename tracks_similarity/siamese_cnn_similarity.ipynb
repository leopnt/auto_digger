{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import librosa\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # to silence librosa warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Lambda, Dropout\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Track:\n",
    "    def __init__(self, filepath: str, sr: int = 22050) -> None:\n",
    "        self.filepath = filepath\n",
    "        self.audio, self.sr = librosa.load(filepath, mono=True, sr=sr)\n",
    "    \n",
    "    def _normalize_mel_spectrogram(mel_spec: np.ndarray) -> np.ndarray:\n",
    "        max_val = np.max(mel_spec)\n",
    "        min_val = np.min(mel_spec)\n",
    "        normalized_spectrogram = (mel_spec - min_val) / (max_val - min_val)\n",
    "\n",
    "        return normalized_spectrogram\n",
    "    \n",
    "    def audio_extract(self, from_sec: int, to_sec: int) -> np.ndarray:\n",
    "        from_idx = from_sec * self.sr\n",
    "        to_idx = to_sec * self.sr\n",
    "\n",
    "        return self.audio[from_idx:to_idx]\n",
    "    \n",
    "    def spectrogram(self, from_sec: int = 60, to_sec: int = 75) -> np.ndarray:\n",
    "        extract = self.audio_extract(from_sec, to_sec)\n",
    "\n",
    "        spec = librosa.feature.melspectrogram(y=extract, sr=self.sr, hop_length=2048)\n",
    "        spec_db = librosa.power_to_db(S=spec, ref=np.max)\n",
    "        spec_db_norm = Track._normalize_mel_spectrogram(spec_db)\n",
    "\n",
    "        return spec_db_norm\n",
    "    \n",
    "    def tri_spectrogram(self, offset: float = 1.0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Take 3 spectrogram of n seconds at 25%, 50% and 75% of the track into one\n",
    "        Params\n",
    "        ======\n",
    "        `offset`: offset the start of the spectrograms by `offset` percent.\n",
    "        Usefull for data augmentation\n",
    "        \"\"\"\n",
    "        total_length_sec = len(self.audio) / self.sr\n",
    "        n = 5\n",
    "\n",
    "        start_25 = int(0.25 * offset * total_length_sec)\n",
    "        stop_25 = start_25 + n\n",
    "        start_50 = int(0.50 * offset * total_length_sec)\n",
    "        stop_50 = start_50 + n\n",
    "        start_75 = int(0.75 * offset * total_length_sec)\n",
    "        stop_75 = start_75 + n\n",
    "\n",
    "        spec_1 = self.spectrogram(start_25, stop_25)\n",
    "        spec_2 = self.spectrogram(start_50, stop_50)\n",
    "        spec_3 = self.spectrogram(start_75, stop_75)\n",
    "\n",
    "        return np.concatenate([spec_1, spec_2, spec_3], axis=1)\n",
    "\n",
    "class TrackPair:\n",
    "    def __init__(self, filepath_left: str, filepath_right: str, similar: bool) -> None:\n",
    "        self.left = Track(filepath_left)\n",
    "        self.right = Track(filepath_right)\n",
    "        self.similar = similar\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, data_path: str, frac: int = 1.0) -> None:\n",
    "        \"\"\"\n",
    "        Build dataset of pairs given a path to the data folder. This folder should look like:\n",
    "\n",
    "        ```\n",
    "\n",
    "        data\n",
    "            different\n",
    "            |   pair_0\n",
    "            |   |   track_a.mp3\n",
    "            |   |   track_b.aif\n",
    "            |   pair_1\n",
    "            |   |   track_c.m4a\n",
    "            |   |   track_b.aiff\n",
    "            |   ...\n",
    "            similar\n",
    "                pair_0\n",
    "                |   track_d.aif\n",
    "                |   track_e.aiff\n",
    "                pair_1\n",
    "                |   track_z.mp3\n",
    "                |   track_b.aiff\n",
    "                ...\n",
    "        ```\n",
    "        \"\"\"\n",
    "\n",
    "        self.trackpairs: list[TrackPair] = []\n",
    "\n",
    "        similars = sorted(glob(f\"{data_path}/similar/*\"))\n",
    "        limit = round(frac * len(similars))\n",
    "        print(\"Loading similar tracks\")\n",
    "        for similar in tqdm(similars[:limit]):\n",
    "            file_pair = sorted(glob(f\"{similar}/*\"))\n",
    "            track_pair = TrackPair(file_pair[0], file_pair[1], 1)\n",
    "            self.trackpairs.append(track_pair)\n",
    "\n",
    "\n",
    "        differents = sorted(glob(f\"{data_path}/different/*\"))\n",
    "        limit = round(frac * len(differents))\n",
    "        print(\"Loading different tracks\")\n",
    "        for different in tqdm(differents[:limit]):\n",
    "            file_pair = sorted(glob(f\"{different}/*\"))\n",
    "            track_pair = TrackPair(file_pair[0], file_pair[1], 0)\n",
    "            self.trackpairs.append(track_pair)\n",
    "\n",
    "    def as_dataframe(self) -> pd.DataFrame:\n",
    "        data = {\"left\": [], \"right\": [], \"similar\": []}\n",
    "\n",
    "        for track_pair in self.trackpairs:\n",
    "            data[\"left\"].append(track_pair.left.filepath)\n",
    "            data[\"right\"].append(track_pair.right.filepath)\n",
    "            data[\"similar\"].append(int(track_pair.similar))\n",
    "        \n",
    "        return pd.DataFrame(data)\n",
    "    \n",
    "    def as_training_data(self) -> tuple[np.ndarray, np.ndarray]:\n",
    "        pairs = []\n",
    "        labels = []\n",
    "\n",
    "        for track_pair in self.trackpairs:\n",
    "            for _ in range(10): # data augmentation. take random parts of the track\n",
    "                offset = random.random()\n",
    "                pairs.append([track_pair.left.tri_spectrogram(offset), track_pair.right.tri_spectrogram(offset)])\n",
    "                labels.append(track_pair.similar)\n",
    "        \n",
    "        return np.array(pairs).astype(float), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(\"./data\", 1.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.as_dataframe().sample(frac=1.0, random_state=0).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.trackpairs[0].left.tri_spectrogram().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.trackpairs[0].right.tri_spectrogram().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spec(track: Track):\n",
    "    plt.figure(figsize=(10, 2))\n",
    "\n",
    "    librosa.display.specshow(track.tri_spectrogram(), y_axis='linear')\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.title(os.path.basename(track.filepath))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot similar\n",
    "for trackpair in dataset.trackpairs[:3]:\n",
    "    print(f\"Similar: {trackpair.similar}\")\n",
    "    plot_spec(trackpair.left)\n",
    "    plot_spec(trackpair.right)\n",
    "\n",
    "# plot different\n",
    "for trackpair in dataset.trackpairs[70:73]:\n",
    "    print(f\"Similar: {trackpair.similar}\")\n",
    "    plot_spec(trackpair.left)\n",
    "    plot_spec(trackpair.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = dataset.as_training_data()\n",
    "X = np.expand_dims(X, axis=-1)\n",
    "y = np.float32(y)\n",
    "\n",
    "print(f\"X.shape: {X.shape}\")\n",
    "print(f\"y.shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X.shape[2:]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_network(input_shape):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    \n",
    "    x = Conv2D(32, (3, 3), activation='relu')(input_tensor)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "\n",
    "    return Model(inputs=input_tensor, outputs=x)\n",
    "\n",
    "def euclidean_distance(vectors):\n",
    "    x, y = vectors\n",
    "    sum_squared = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_squared, K.epsilon()))\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, _ = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "def create_siamese_network(input_shape):\n",
    "    input_a = Input(shape=input_shape, name=\"left_input\")\n",
    "    input_b = Input(shape=input_shape, name=\"right_input\")\n",
    "    \n",
    "    base_network = create_base_network(input_shape)\n",
    "    \n",
    "    processed_a = base_network(input_a)\n",
    "    processed_b = base_network(input_b)\n",
    "    \n",
    "    distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "    \n",
    "    model = Model([input_a, input_b], distance)\n",
    "    return model\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    margin = 1.0\n",
    "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    y_pred = tf.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true * y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1 - y_true) * (1 - y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1 - y_true) * y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true * (1 - y_pred), 'float'), axis=0)\n",
    "\n",
    "    precision = tp / (tp + fp + K.epsilon())\n",
    "    recall = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "    return K.mean(f1)\n",
    "\n",
    "model = create_siamese_network(input_shape)\n",
    "model.compile(loss=contrastive_loss, optimizer=Adam(learning_rate=0.0001), metrics=[f1_score])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    [X_train[:,0], X_train[:,1]],\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    batch_size=8,\n",
    "    validation_data=([X_test[:,0], X_test[:,1]], y_test),\n",
    ")\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['f1_score'])\n",
    "plt.plot(history.history['val_f1_score'])\n",
    "plt.title('model f1_score')\n",
    "plt.ylabel('f1_score')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = TrackPair(\n",
    "    \"/Users/leopnt/Music/TR4X/House/Sweely - Time for Freakness/02 - Sweely - Move for Me.mp3\",\n",
    "    \"/Users/leopnt/Music/TR4X/House/Sweely - Time for Freakness/02 - Sweely - Move for Me.mp3\",\n",
    "    1\n",
    ")\n",
    "\n",
    "plot_spec(pair.left)\n",
    "plot_spec(pair.right)\n",
    "\n",
    "X_new = [\n",
    "    pair.left.tri_spectrogram().reshape(1, input_shape[0], input_shape[1]),\n",
    "    pair.right.tri_spectrogram().reshape(1, input_shape[0], input_shape[1])]\n",
    "model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(model.predict([X_test[:,0], X_test[:,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
