{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "import librosa\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # to silence librosa warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2048)])\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Flatten, Dense, Lambda, Dropout, GlobalAveragePooling1D, GlobalMaxPooling1D, Concatenate, LeakyReLU\n",
    "from tensorflow.keras.optimizers.legacy import Adam, RMSprop\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from triplet_dataset import TripletDataset\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spec(spec: np.ndarray):\n",
    "    plt.figure(figsize=(10, 2))\n",
    "\n",
    "    librosa.display.specshow(spec, y_axis='mel')\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use data generated from script generate training data\n",
    "X, y = joblib.load(\"data_n2.joblib\")\n",
    "\n",
    "print(f\"X.shape: {X.shape}\")\n",
    "print(f\"y.shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check input data\n",
    "print(f\"Label: {y[0]}\")\n",
    "plot_spec(X[0][0])\n",
    "plot_spec(X[0][1])\n",
    "\n",
    "print(f\"Label: {y[-7]}\")\n",
    "plot_spec(X[-7][0])\n",
    "plot_spec(X[-7][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X.shape[2:]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalL2Pooling1D(tf.keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        return tf.sqrt(tf.reduce_sum(tf.square(inputs), axis=1))\n",
    "\n",
    "leaky_relu_layer = LeakyReLU(alpha=0.01)\n",
    "\n",
    "def euclidean_distance(embeddings):\n",
    "    x, y = embeddings\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, _ = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "def contrastive_loss_with_margin(margin):\n",
    "    def contrastive_loss(y_true, y_pred):\n",
    "        square_pred = K.square(y_pred)\n",
    "        margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "        return (y_true * square_pred + (1 - y_true) * margin_square)\n",
    "    return contrastive_loss\n",
    "\n",
    "# Base network is from:\n",
    "# (1) Recommending music on Spotify with deep learning. Sander Dieleman. https://sander.ai/2014/08/05/spotify-cnns.html (accessed 2024-03-23).\n",
    "def build_base_network(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv1D(filters=256, kernel_size=4, activation=leaky_relu_layer)(inputs)\n",
    "    x = MaxPooling1D(pool_size=4)(x)\n",
    "\n",
    "    x = Conv1D(filters=256, kernel_size=4, activation=leaky_relu_layer)(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "    x = Conv1D(filters=512, kernel_size=4, activation=leaky_relu_layer)(x)\n",
    "\n",
    "    # global temporal pooling\n",
    "    mean_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    l2_pool = GlobalL2Pooling1D()(x)\n",
    "\n",
    "    pooled_features = Concatenate()([mean_pool, max_pool, l2_pool])\n",
    "\n",
    "    x = Dense(2048, activation=leaky_relu_layer)(pooled_features)\n",
    "    x = Dense(2048, activation=leaky_relu_layer)(x)\n",
    "\n",
    "    outputs = Dense(40)(x)\n",
    "\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "def build_siamese_network(base_network, input_shape):\n",
    "    input_left = Input(shape=input_shape, name=\"input_left\")\n",
    "    input_right = Input(shape=input_shape, name=\"input_right\")\n",
    "\n",
    "    embeddings_left = base_network(input_left)\n",
    "    embeddings_right = base_network(input_right)\n",
    "\n",
    "    outputs = Lambda(euclidean_distance, name='output_layer',\n",
    "        output_shape=eucl_dist_output_shape)([embeddings_left, embeddings_right])\n",
    "    \n",
    "    siamese_network = Model(inputs=[input_left, input_right], outputs=outputs)\n",
    "\n",
    "    return siamese_network\n",
    "\n",
    "base_network = build_base_network(input_shape)\n",
    "model = build_siamese_network(base_network, input_shape)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001), loss=contrastive_loss_with_margin(margin=1.0))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=0)\n",
    "\n",
    "# free up memory\n",
    "del X\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    [X_train[:,0], X_train[:,1]],\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=([X_test[:,0], X_test[:,1]], y_test),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dists = model.predict([X_train[:,0], X_train[:,1]])\n",
    "test_dists = model.predict([X_test[:,0], X_test[:,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.title(\"Predicted distances Train\")\n",
    "sns.histplot(train_dists.ravel())\n",
    "plt.xlim(0.0, 2.0)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title(\"Predicted distances Test\")\n",
    "sns.histplot(test_dists.ravel())\n",
    "plt.xlim(0.0, 2.0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y_true, y_pred):\n",
    "    return np.mean(y_pred == y_true)\n",
    "\n",
    "y_pred_train = (train_dists < np.mean(test_dists)).ravel().astype(int)\n",
    "train_accuracy = compute_accuracy(y_train, y_pred_train)\n",
    "\n",
    "y_pred_val = (test_dists < np.mean(test_dists)).ravel().astype(int)\n",
    "val_accuracy = compute_accuracy(y_test, y_pred_val)\n",
    "\n",
    "print(\"Train Accuracy = {} Val accuracy = {}\".format(train_accuracy, val_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, 1 - test_dists)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_val)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('siamese_model_n2.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
